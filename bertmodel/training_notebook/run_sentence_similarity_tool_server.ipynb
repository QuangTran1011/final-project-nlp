{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_RYEvD_ddfv"
      },
      "outputs": [],
      "source": [
        "!pip install pyngrok\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wOZ6xQ6ZgNQ4"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from transformers import BertTokenizer\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks/bertmodel/new')\n",
        "from bert import minBert\n",
        "from bert import EncoderLayer, SelfAttention, FeedForward, BaseAttention\n",
        "from positional_embedding import PositionalEmbedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzujV2hMgN-F"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Ane5k3cgODz"
      },
      "outputs": [],
      "source": [
        "min_bert_layer = tf.keras.models.load_model(\n",
        "    '/content/drive/MyDrive/Colab Notebooks/bertmodel/min_bert_layer_after_training_qqp_triplet_v3.keras',\n",
        "    custom_objects={\n",
        "        \"minBert\": minBert,\n",
        "        \"EncoderLayer\": EncoderLayer,\n",
        "        \"SelfAttention\": SelfAttention,\n",
        "        \"FeedForward\": FeedForward,\n",
        "        \"BaseAttention\" : BaseAttention,\n",
        "        \"PositionalEmbedding\" : PositionalEmbedding\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sQ6fyORGgOGR"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "def tokenize(sentence):\n",
        "    return tokenizer(sentence, return_tensors=\"tf\", add_special_tokens=True, padding='max_length', truncation=True, max_length=256)['input_ids']\n",
        "\n",
        "def model_embedding(model, sentence):\n",
        "    sentence_tokenized = tokenize(sentence)\n",
        "    return model(sentence_tokenized, training=False)[:, 0, :].numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "R0kXIZb9gOI-"
      },
      "outputs": [],
      "source": [
        "def compute_sentence_similarity(sentence_1, sentence_2):\n",
        "  embedded_sentence_1 = model_embedding(min_bert_layer, sentence_1)\n",
        "  embedded_sentence_2 = model_embedding(min_bert_layer, sentence_2)\n",
        "\n",
        "  return round(cosine_similarity(embedded_sentence_1, embedded_sentence_2).item(), 2) * 100"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_most_similar(query, dataset):\n",
        "    # Lấy embedding của câu query và dataset\n",
        "    query_embedding = model_embedding(min_bert_layer, query)\n",
        "    dataset_embeddings = model_embedding(min_bert_layer, dataset)\n",
        "\n",
        "    # Đảm bảo query_embedding và dataset_embeddings là mảng 2D (1, embedding_dim)\n",
        "    query_embedding = np.array(query_embedding).reshape(1, -1)  # Reshape thành mảng 2D nếu cần\n",
        "    dataset_embeddings = np.array(dataset_embeddings)  # Dataset embeddings là mảng 2D\n",
        "\n",
        "    # Tính cosine similarity giữa query_embedding và tất cả các câu trong dataset\n",
        "    similarities = cosine_similarity(query_embedding, dataset_embeddings)\n",
        "\n",
        "    # similarities có kích thước (1, N), tìm index của phần tử có giá trị cao nhất\n",
        "    best_index = np.argmax(similarities)  # Trả về index của phần tử có độ tương đồng cao nhất\n",
        "\n",
        "    # Trả về câu có độ tương đồng cao nhất\n",
        "    return dataset[best_index]"
      ],
      "metadata": {
        "id": "lMH4nH7C2hPa"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NTFj4M6v0-ZG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "\n",
        "def get_top_k_similarities(sentence, embeddings, sentences, k=10):\n",
        "    \"\"\"\n",
        "    Lấy ra chỉ số của k phần tử có similarity cao nhất.\n",
        "\n",
        "    Args:\n",
        "    - similarities: Mảng chứa cosine similarity.\n",
        "    - k: Số lượng phần tử có similarity cao nhất cần lấy (mặc định 10).\n",
        "\n",
        "    Returns:\n",
        "    - top_k_indices: Mảng chứa chỉ số của k phần tử có similarity cao nhất.\n",
        "    \"\"\"\n",
        "\n",
        "    embedded_sentence = model_embedding(min_bert_layer, sentence)\n",
        "    similarities = cosine_similarity(embedded_sentence, embeddings)\n",
        "\n",
        "    if similarities.ndim == 2:\n",
        "      similarities = similarities.flatten()\n",
        "    # Lấy ra chỉ số của k phần tử có similarity cao nhất\n",
        "    top_k_indices = np.argsort(similarities)[-k:][::-1]  # argsort() + đảo ngược để lấy max similarity\n",
        "    top_sentences = [sentences[i] for i in top_k_indices]\n",
        "    return top_sentences\n",
        "\n",
        "# Ví dụ sử dụng\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5jTHaN3ou1MS"
      },
      "outputs": [],
      "source": [
        "def load_data_from_files(sentences_filename='sentences.txt', embeddings_filename='embeddings.pkl'):\n",
        "    # Đọc các câu từ file text\n",
        "    with open(sentences_filename, 'r') as f:\n",
        "        sentences = f.readlines()\n",
        "    sentences = [sentence.strip() for sentence in sentences]  # Loại bỏ ký tự newline\n",
        "\n",
        "    # Đọc embeddings từ file pickle\n",
        "    with open(embeddings_filename, 'rb') as file:\n",
        "        embeddings = pickle.load(file)\n",
        "\n",
        "    return sentences, embeddings\n",
        "\n",
        "# Ví dụ sử dụng:\n",
        "sentences, embeddings = load_data_from_files('/content/drive/MyDrive/Colab Notebooks/bertmodel/quora_sentences.txt', '/content/drive/MyDrive/Colab Notebooks/bertmodel/qoura_embeddings.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "_3cDAKyNijQW"
      },
      "outputs": [],
      "source": [
        "html_content = '''\n",
        "        <!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "\n",
        "<head>\n",
        "  <meta charset=\"UTF-8\">\n",
        "  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "  <meta name=\"description\"\n",
        "    content=\"Tool to compute sentence similarity, find most similar sentence, and search similar sentences\">\n",
        "  <title>Sentence Similarity Tool</title>\n",
        "\n",
        "  <!-- Bootstrap CSS -->\n",
        "  <link href=\"https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css\" rel=\"stylesheet\">\n",
        "\n",
        "  <style>\n",
        "    body {\n",
        "      background-color: #f8f9fa;\n",
        "      font-family: Arial, sans-serif;\n",
        "    }\n",
        "\n",
        "    h1 {\n",
        "      margin-bottom: 20px;\n",
        "    }\n",
        "\n",
        "    .card {\n",
        "      margin-bottom: 20px;\n",
        "    }\n",
        "\n",
        "    .btn-primary {\n",
        "      width: 100%;\n",
        "    }\n",
        "\n",
        "    .result-container {\n",
        "      padding: 15px;\n",
        "      background: #ffffff;\n",
        "      border: 1px solid #ced4da;\n",
        "      border-radius: 5px;\n",
        "      color: #495057;\n",
        "      margin-top: 10px;\n",
        "    }\n",
        "\n",
        "    #loading {\n",
        "      display: none;\n",
        "      color: #007bff;\n",
        "      font-weight: bold;\n",
        "    }\n",
        "  </style>\n",
        "</head>\n",
        "\n",
        "<body>\n",
        "  <div class=\"container mt-5\">\n",
        "    <header class=\"text-center mb-5\">\n",
        "      <h1 class=\"text-primary\">Simple Sentence Similarity Tool</h1>\n",
        "      <p class=\"text-muted\">Trần Văn Quang, Lê Tiến Thực, Nguyễn Việt Cường</p>\n",
        "    </header>\n",
        "\n",
        "    <!-- Compute Sentence Similarity -->\n",
        "    <div class=\"card shadow-sm\">\n",
        "      <div class=\"card-body\">\n",
        "        <h2 class=\"h5\">Compute Sentence Similarity</h2>\n",
        "        <div class=\"mb-3\">\n",
        "          <label for=\"sentence_1\" class=\"form-label\">Sentence 1</label>\n",
        "          <input type=\"text\" id=\"sentence_1\" class=\"form-control\" placeholder=\"Enter the first sentence\" required>\n",
        "        </div>\n",
        "        <div class=\"mb-3\">\n",
        "          <label for=\"sentence_2\" class=\"form-label\">Sentence 2</label>\n",
        "          <input type=\"text\" id=\"sentence_2\" class=\"form-control\" placeholder=\"Enter the second sentence\" required>\n",
        "        </div>\n",
        "        <button type=\"button\" class=\"btn btn-primary\" onclick=\"getPrediction()\">Get Prediction</button>\n",
        "        <div id=\"predictionResult\" class=\"result-container mt-3 d-none\"></div>\n",
        "      </div>\n",
        "    </div>\n",
        "\n",
        "    <!-- Compute Most Similar Sentence -->\n",
        "    <div class=\"card shadow-sm\">\n",
        "      <div class=\"card-body\">\n",
        "        <h2 class=\"h5\">Compute Most Similar Sentence</h2>\n",
        "        <div class=\"mb-3\">\n",
        "          <label for=\"sentence_query\" class=\"form-label\">Query Sentence</label>\n",
        "          <input type=\"text\" id=\"sentence_query\" class=\"form-control\" placeholder=\"Enter a query sentence\" required>\n",
        "        </div>\n",
        "        <div class=\"mb-3\">\n",
        "          <label for=\"sentence_dataset\" class=\"form-label\">Dataset (One sentence per line)</label>\n",
        "          <textarea id=\"sentence_dataset\" class=\"form-control\" rows=\"5\"\n",
        "            placeholder=\"Enter sentences separated by new lines\"></textarea>\n",
        "        </div>\n",
        "        <button type=\"button\" class=\"btn btn-primary\" onclick=\"getMostSimilarSentence()\">Get Most Similar\n",
        "          Sentence</button>\n",
        "        <div id=\"mostSimilarityResult\" class=\"result-container mt-3 d-none\"></div>\n",
        "      </div>\n",
        "    </div>\n",
        "\n",
        "    <!-- Search Similar Sentences -->\n",
        "    <div class=\"card shadow-sm\">\n",
        "      <div class=\"card-body\">\n",
        "        <h2 class=\"h5\">Search Similar Sentences</h2>\n",
        "        <div class=\"mb-3\">\n",
        "          <label for=\"required_sentence\" class=\"form-label\">Sentence to Search</label>\n",
        "          <input type=\"text\" id=\"required_sentence\" class=\"form-control\"\n",
        "            placeholder=\"Enter a sentence to find similar ones\" required>\n",
        "        </div>\n",
        "        <button type=\"button\" class=\"btn btn-primary\" onclick=\"getSimilarSentences()\">Get Similar Sentences</button>\n",
        "        <div id=\"predictionResultForSearch\" class=\"result-container mt-3 d-none\"></div>\n",
        "      </div>\n",
        "    </div>\n",
        "  </div>\n",
        "\n",
        "  <!-- Bootstrap Bundle with Popper -->\n",
        "  <!-- <script src=\"https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js\"></script> -->\n",
        "\n",
        "  <script>\n",
        "    async function getPrediction() {\n",
        "      const sentence_1 = document.getElementById('sentence_1').value;\n",
        "      const sentence_2 = document.getElementById('sentence_2').value;\n",
        "\n",
        "      const resultDiv = document.getElementById('predictionResult');\n",
        "      resultDiv.classList.add('d-none');\n",
        "      resultDiv.innerText = \"Loading...\";\n",
        "\n",
        "      const response = await fetch('/getprediction', {\n",
        "        method: 'POST',\n",
        "        headers: { 'Content-Type': 'application/json' },\n",
        "        body: JSON.stringify({ sentence_1, sentence_2 })\n",
        "      });\n",
        "\n",
        "      const data = await response.json();\n",
        "      resultDiv.classList.remove('d-none');\n",
        "      resultDiv.innerText = `Similarity: ${data.prediction}%`;\n",
        "    }\n",
        "\n",
        "    async function getMostSimilarSentence() {\n",
        "      const sentence_query = document.getElementById('sentence_query').value;\n",
        "      const sentence_dataset = document.getElementById('sentence_dataset').value.split('\\\\n');\n",
        "\n",
        "      const resultDiv = document.getElementById('mostSimilarityResult');\n",
        "      resultDiv.classList.add('d-none');\n",
        "      resultDiv.innerText = \"Loading...\";\n",
        "\n",
        "      const response = await fetch('/getmostsimilarsentence', {\n",
        "        method: 'POST',\n",
        "        headers: { 'Content-Type': 'application/json' },\n",
        "        body: JSON.stringify({ sentence_query, sentence_dataset })\n",
        "      });\n",
        "\n",
        "      const data = await response.json();\n",
        "      resultDiv.classList.remove('d-none');\n",
        "      resultDiv.innerText = `Most Similar Sentence: ${data.most_similar_sentence}`;\n",
        "    }\n",
        "\n",
        "    async function getSimilarSentences() {\n",
        "      const required_sentence = document.getElementById('required_sentence').value;\n",
        "\n",
        "      const resultContainer = document.getElementById('predictionResultForSearch');\n",
        "      resultContainer.classList.add('d-none');\n",
        "      resultContainer.innerHTML = \"Loading...\";\n",
        "\n",
        "      const response = await fetch('/getsimilarsentences', {\n",
        "        method: 'POST',\n",
        "        headers: { 'Content-Type': 'application/json' },\n",
        "        body: JSON.stringify({ required_sentence })\n",
        "      });\n",
        "\n",
        "      const data = await response.json();\n",
        "      resultContainer.classList.remove('d-none');\n",
        "      resultContainer.innerHTML = '';\n",
        "\n",
        "      const ol = document.createElement('ol');\n",
        "      data.similar_sentences.forEach(sentence => {\n",
        "        const li = document.createElement('li');\n",
        "        li.textContent = sentence;\n",
        "        ol.appendChild(li);\n",
        "      });\n",
        "      resultContainer.appendChild(ol);\n",
        "    }\n",
        "    console.log(\"Script loaded\");\n",
        "    console.log(\"getPrediction function loaded\");\n",
        "\n",
        "  </script>\n",
        "</body>\n",
        "\n",
        "</html>\n",
        "                  '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTy52oHQzv_c",
        "outputId": "9dca828c-e934-4257-d003-90803a93dc44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ngrok tunnel URL: NgrokTunnel: \"https://0e9c-34-106-123-145.ngrok-free.app\" -> \"http://localhost:5000\"\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [29/Nov/2024 08:35:52] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [29/Nov/2024 08:35:53] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
          ]
        }
      ],
      "source": [
        "from flask import Flask, request, jsonify\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Khởi tạo Flask app\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Mở một ngrok tunnel và tạo URL công cộng cho Flask app\n",
        "ngrok.set_auth_token(\"2EFKzjuZu7fVrLtjfCDWaEb1Lkz_pDEkWPKv8JS8Uqvtcsd\")\n",
        "public_url = ngrok.connect(5000)\n",
        "print(f\"Ngrok tunnel URL: {public_url}\")\n",
        "\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return html_content\n",
        "\n",
        "@app.route('/getprediction', methods=['POST'])\n",
        "def get_prediction():\n",
        "    # Lấy dữ liệu từ request\n",
        "    data = request.get_json()\n",
        "    sentence_1 = data['sentence_1']\n",
        "    sentence_2 = data['sentence_2']\n",
        "\n",
        "    similarity = compute_sentence_similarity(sentence_1, sentence_2)\n",
        "\n",
        "    # Trả về kết quả dưới dạng JSON (ở đây giả sử dự đoán dựa trên chiều cao)\n",
        "    return jsonify({'prediction': similarity})  # Ví dụ tính toán\n",
        "\n",
        "@app.route('/getsimilarsentences', methods=['POST'])\n",
        "def get_similar_sentences():\n",
        "    data = request.get_json()\n",
        "    sentence = data['required_sentence']\n",
        "    similarity_list = get_top_k_similarities(sentence, embeddings, sentences)\n",
        "    return jsonify({'similar_sentences': similarity_list})\n",
        "\n",
        "@app.route('/getmostsimilarsentence', methods=['POST'])\n",
        "def get_most_similar_sentence():\n",
        "    data = request.get_json()\n",
        "    sentence_query = data['sentence_query']\n",
        "    sentence_dataset = data['sentence_dataset']\n",
        "    most_similar_sentence = find_most_similar(sentence_query, sentence_dataset)\n",
        "    return jsonify({'most_similar_sentence': most_similar_sentence})\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Chạy Flask trên cổng 5000\n",
        "    app.run(port=5000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ETnnwFXxu1Hv"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "def save_embeddings_with_pickle_batch(sentences, model, batch_size=64, sentences_filename='sentences.txt', embeddings_filename='embeddings.pkl'):\n",
        "    \"\"\"\n",
        "    Lưu các câu vào file text và embeddings vào file pickle với xử lý theo batch.\n",
        "\n",
        "    Args:\n",
        "    - sentences: mảng các câu cần tính embedding.\n",
        "    - model: mô hình để tính embedding.\n",
        "    - batch_size: kích thước batch khi tính embedding.\n",
        "    - sentences_filename: tên file text để lưu trữ các câu.\n",
        "    - embeddings_filename: tên file pickle để lưu trữ embeddings.\n",
        "    \"\"\"\n",
        "    embeddings = []\n",
        "\n",
        "    # Xử lý các câu theo từng batch\n",
        "    for i in range(0, len(sentences), batch_size):\n",
        "        batch_sentences = sentences[i:i+batch_size]  # Lấy batch\n",
        "        batch_tokenized = tokenize(batch_sentences)  # Tokenize batch\n",
        "        batch_embeddings = model(batch_tokenized, training=False)[:, 0, :].numpy()  # Lấy embeddings cho batch\n",
        "        embeddings.append(batch_embeddings)  # Thêm embeddings của batch vào list\n",
        "\n",
        "        print(f\"Processed batch {i // batch_size + 1}/{(len(sentences) - 1) // batch_size + 1}\")\n",
        "\n",
        "    # Chuyển list embeddings thành mảng numpy\n",
        "    embeddings_array = np.concatenate(embeddings, axis=0)\n",
        "\n",
        "    # Lưu các câu vào file text\n",
        "    with open(sentences_filename, 'w') as f:\n",
        "        for sentence in sentences:\n",
        "            f.write(sentence + '\\n')\n",
        "\n",
        "    # Lưu mảng embeddings vào file pickle\n",
        "    with open(embeddings_filename, 'wb') as file:\n",
        "        pickle.dump(embeddings_array, file)\n",
        "\n",
        "    print(f\"Sentences saved to {sentences_filename}\")\n",
        "    print(f\"Embeddings saved to {embeddings_filename}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}