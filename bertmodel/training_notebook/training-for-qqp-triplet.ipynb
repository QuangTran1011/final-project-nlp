{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T05:58:24.365979Z",
     "iopub.status.busy": "2024-11-28T05:58:24.365555Z",
     "iopub.status.idle": "2024-11-28T05:58:29.066085Z",
     "shell.execute_reply": "2024-11-28T05:58:29.065107Z",
     "shell.execute_reply.started": "2024-11-28T05:58:24.365951Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer\n",
    "import sys\n",
    "sys.path.append('/kaggle/input/new')\n",
    "from bert import minBert\n",
    "from bert import EncoderLayer, SelfAttention, FeedForward, BaseAttention\n",
    "from positional_embedding import PositionalEmbedding\n",
    "sys.path.append('/kaggle/input/contrastive_learning')\n",
    "from contrastive_learning import QqpTripletSupervisedContrastiveModel as SupervisedContrastiveModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T05:58:29.067923Z",
     "iopub.status.busy": "2024-11-28T05:58:29.067453Z",
     "iopub.status.idle": "2024-11-28T05:58:29.379120Z",
     "shell.execute_reply": "2024-11-28T05:58:29.378317Z",
     "shell.execute_reply.started": "2024-11-28T05:58:29.067895Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "min_bert_layer = tf.keras.models.load_model(\n",
    "    '/kaggle/input/min_bert_layer.keras',\n",
    "    custom_objects={\n",
    "        \"minBert\": minBert,\n",
    "        \"EncoderLayer\": EncoderLayer,\n",
    "        \"SelfAttention\": SelfAttention,\n",
    "        \"FeedForward\": FeedForward,\n",
    "        \"BaseAttention\" : BaseAttention,\n",
    "        \"PositionalEmbedding\" : PositionalEmbedding\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T08:54:17.216589Z",
     "iopub.status.busy": "2024-11-28T08:54:17.215872Z",
     "iopub.status.idle": "2024-11-28T08:54:19.026995Z",
     "shell.execute_reply": "2024-11-28T08:54:19.026303Z",
     "shell.execute_reply.started": "2024-11-28T08:54:17.216555Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load SNLI dataset\n",
    "dataset = load_dataset(\"embedding-data/QQP_triplets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T08:54:15.122194Z",
     "iopub.status.busy": "2024-11-28T08:54:15.121844Z",
     "iopub.status.idle": "2024-11-28T08:54:15.130515Z",
     "shell.execute_reply": "2024-11-28T08:54:15.129557Z",
     "shell.execute_reply.started": "2024-11-28T08:54:15.122162Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(dataset, tokenizer, batch_size=32, max_length=256):\n",
    "    anchors = []\n",
    "    positives = []\n",
    "    negatives = []\n",
    "\n",
    "    sample_list = []\n",
    "\n",
    "    for sample in dataset['set']:\n",
    "        if len(sample['neg']) != 30: continue\n",
    "        anchors.append(sample['query'])\n",
    "        positives.append(sample['pos'][0])\n",
    "        negatives.append(sample['neg'])\n",
    "        sample_list.append(sample['pos'] + sample['neg'])\n",
    "    \n",
    "    print(\"Tổng số anchors:\", len(anchors))\n",
    "    print(\"Tổng số positives:\", len(positives))\n",
    "    print(\"Tổng số negatives:\", len(negatives))\n",
    "    # Kiểm tra xem có giá trị None hay không trong dữ liệu đầu vào\n",
    "    if any(val is None for val in anchors + positives + negatives):\n",
    "        print(\"Cảnh báo: Tìm thấy None trong các dữ liệu đầu vào!\")\n",
    "\n",
    "    # Tiến hành tokenization\n",
    "    def tokenize_texts(texts):\n",
    "        encodings = tokenizer(texts, padding='max_length', truncation=True, max_length=max_length, return_tensors=\"tf\")\n",
    "        return encodings\n",
    "\n",
    "    anchor_encodings = tokenize_texts(anchors)\n",
    "    positive_encodings = tokenize_texts(positives)\n",
    "    negative_encodings = [tokenize_texts(negative) for negative in negatives]\n",
    "\n",
    "    if anchor_encodings is None or positive_encodings is None or negative_encodings is None:\n",
    "        print(\"Cảnh báo: Tokenizer không thành công với một số mẫu!\")\n",
    "\n",
    "    # Tạo tf.data.Dataset\n",
    "    dataset = {\n",
    "        'anchors': anchor_encodings['input_ids'],\n",
    "        'positives': positive_encodings['input_ids'],\n",
    "        'negatives': [negative_encoding['input_ids'] for negative_encoding in negative_encodings],\n",
    "        'anchor_sentences': anchors,\n",
    "        'sample_sentences': sample_list\n",
    "    }\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T12:08:12.420154Z",
     "iopub.status.busy": "2024-11-28T12:08:12.419779Z",
     "iopub.status.idle": "2024-11-28T12:08:48.172072Z",
     "shell.execute_reply": "2024-11-28T12:08:48.171382Z",
     "shell.execute_reply.started": "2024-11-28T12:08:12.420121Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số anchors: 4213\n",
      "Tổng số positives: 4213\n",
      "Tổng số negatives: 4213\n"
     ]
    }
   ],
   "source": [
    "train_dataset = prepare_data(dataset['train'][16000:21000], tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T08:54:23.962389Z",
     "iopub.status.busy": "2024-11-28T08:54:23.961660Z",
     "iopub.status.idle": "2024-11-28T08:54:31.002135Z",
     "shell.execute_reply": "2024-11-28T08:54:31.001257Z",
     "shell.execute_reply.started": "2024-11-28T08:54:23.962355Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số anchors: 839\n",
      "Tổng số positives: 839\n",
      "Tổng số negatives: 839\n"
     ]
    }
   ],
   "source": [
    "test_dataset = prepare_data(dataset['train'][5001: 6000], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T08:58:30.491450Z",
     "iopub.status.busy": "2024-11-28T08:58:30.491146Z",
     "iopub.status.idle": "2024-11-28T08:58:30.496218Z",
     "shell.execute_reply": "2024-11-28T08:58:30.495248Z",
     "shell.execute_reply.started": "2024-11-28T08:58:30.491423Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_tf_dataset(train_data, batch_size=32):\n",
    "    # Chuyển thành tf.data.Dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((train_data['anchors'], train_data['positives'], train_data['negatives']))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T12:08:53.487655Z",
     "iopub.status.busy": "2024-11-28T12:08:53.486839Z",
     "iopub.status.idle": "2024-11-28T12:08:54.253514Z",
     "shell.execute_reply": "2024-11-28T12:08:54.252501Z",
     "shell.execute_reply.started": "2024-11-28T12:08:53.487620Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tf_train_dataset = create_tf_dataset(train_dataset, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T05:59:30.695430Z",
     "iopub.status.busy": "2024-11-28T05:59:30.694579Z",
     "iopub.status.idle": "2024-11-28T05:59:30.710612Z",
     "shell.execute_reply": "2024-11-28T05:59:30.709673Z",
     "shell.execute_reply.started": "2024-11-28T05:59:30.695396Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = SupervisedContrastiveModel(min_bert_layer)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T05:59:32.568743Z",
     "iopub.status.busy": "2024-11-28T05:59:32.568008Z",
     "iopub.status.idle": "2024-11-28T05:59:32.572586Z",
     "shell.execute_reply": "2024-11-28T05:59:32.571674Z",
     "shell.execute_reply.started": "2024-11-28T05:59:32.568706Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tf.config.experimental_run_functions_eagerly(True)  # Bật eager execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T12:09:00.759083Z",
     "iopub.status.busy": "2024-11-28T12:09:00.758476Z",
     "iopub.status.idle": "2024-11-28T12:42:24.434332Z",
     "shell.execute_reply": "2024-11-28T12:42:24.433476Z",
     "shell.execute_reply.started": "2024-11-28T12:09:00.759048Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1054/1054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2004s\u001b[0m 2s/step - loss: 3.3661\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7b7e493978b0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tf_train_dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T12:49:38.771916Z",
     "iopub.status.busy": "2024-11-28T12:49:38.771054Z",
     "iopub.status.idle": "2024-11-28T12:49:39.088857Z",
     "shell.execute_reply": "2024-11-28T12:49:39.088127Z",
     "shell.execute_reply.started": "2024-11-28T12:49:38.771879Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "min_bert_layer.save(\"min_bert_layer_after_training_qqp_triplet_v3.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T08:54:40.097533Z",
     "iopub.status.busy": "2024-11-28T08:54:40.096959Z",
     "iopub.status.idle": "2024-11-28T08:54:40.102421Z",
     "shell.execute_reply": "2024-11-28T08:54:40.101498Z",
     "shell.execute_reply.started": "2024-11-28T08:54:40.097484Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "queries = test_dataset['anchor_sentences']\n",
    "sample_sentences_list = test_dataset['sample_sentences']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T08:54:48.310375Z",
     "iopub.status.busy": "2024-11-28T08:54:48.309792Z",
     "iopub.status.idle": "2024-11-28T08:54:48.316393Z",
     "shell.execute_reply": "2024-11-28T08:54:48.315568Z",
     "shell.execute_reply.started": "2024-11-28T08:54:48.310341Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def find_most_similar(query, dataset, model, tokenizer):\n",
    "    query_encoding = tokenizer(query, return_tensors=\"tf\", add_special_tokens=True, padding='max_length', truncation=True, max_length=256)\n",
    "    query_embedding = model(query_encoding[\"input_ids\"], training=False)[:,0,:]\n",
    "    dataset_embeddings = model(tokenizer(dataset, return_tensors=\"tf\", add_special_tokens=True, padding='max_length', truncation=True, max_length=256)[\"input_ids\"], training=False)[:,0,:]\n",
    "    similarities = tf.keras.losses.cosine_similarity(query_embedding, dataset_embeddings)\n",
    "    return tf.argmax(-similarities).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T12:47:03.093105Z",
     "iopub.status.busy": "2024-11-28T12:47:03.092761Z",
     "iopub.status.idle": "2024-11-28T12:48:50.682477Z",
     "shell.execute_reply": "2024-11-28T12:48:50.681711Z",
     "shell.execute_reply.started": "2024-11-28T12:47:03.093078Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "correct_count = 0\n",
    "for i in range(len(queries)):\n",
    "    most_similar = find_most_similar(queries[i], sample_sentences_list[i], min_bert_layer, tokenizer)\n",
    "    if most_similar == 0:\n",
    "        correct_count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T12:49:10.134582Z",
     "iopub.status.busy": "2024-11-28T12:49:10.134179Z",
     "iopub.status.idle": "2024-11-28T12:49:10.139346Z",
     "shell.execute_reply": "2024-11-28T12:49:10.138436Z",
     "shell.execute_reply.started": "2024-11-28T12:49:10.134548Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 667 sentences, percentage: 0.7949940405244339\n"
     ]
    }
   ],
   "source": [
    "print(f\"correct: {correct_count} sentences, percentage: {correct_count / len(queries)}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6127937,
     "sourceId": 10026252,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
