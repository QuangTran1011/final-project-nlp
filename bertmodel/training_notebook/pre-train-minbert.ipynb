{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10024169,"sourceType":"datasetVersion","datasetId":6127937}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport sys\nsys.path.append('/kaggle/input/new')\nfrom positional_embedding import PositionalEmbedding\nfrom bert import minBert\nfrom bert import EncoderLayer, SelfAttention, FeedForward, BaseAttention\nimport sentencepiece as spm\nfrom transformers import BertTokenizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T01:54:10.617437Z","iopub.execute_input":"2024-11-27T01:54:10.618278Z","iopub.status.idle":"2024-11-27T01:54:14.256420Z","shell.execute_reply.started":"2024-11-27T01:54:10.618240Z","shell.execute_reply":"2024-11-27T01:54:14.255678Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"mlm_data = pd.read_csv('/kaggle/input/bertmodel/bookcorpus.csv')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T01:54:58.694826Z","iopub.execute_input":"2024-11-27T01:54:58.695565Z","iopub.status.idle":"2024-11-27T01:55:00.078847Z","shell.execute_reply.started":"2024-11-27T01:54:58.695528Z","shell.execute_reply":"2024-11-27T01:55:00.077863Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5530773c085474db856a8e01b122400"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3bcb6f3c68040e6ae3cbdab81e3f5b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4acc75538c24b8abe717f2a9473b8b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"780f52722aed4dd794b56649e630d411"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"cls_token_id = tokenizer.cls_token_id\nsep_token_id = tokenizer.sep_token_id\npad_token_id = tokenizer.pad_token_id\nunk_token_id = tokenizer.unk_token_id\nmask_token_id = tokenizer.mask_token_id\nvocab_size = tokenizer.vocab_size\n\nprint(f\"CLS Token ID: {cls_token_id}\")\nprint(f\"SEP Token ID: {sep_token_id}\")\nprint(f\"PAD Token ID: {pad_token_id}\")\nprint(f\"UNK Token ID: {unk_token_id}\")\nprint(f\"MASK Token ID: {mask_token_id}\")\nprint(f\"Vocab size: {vocab_size}\")\n\n","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["CLS Token ID: 101","SEP Token ID: 102","PAD Token ID: 0","UNK Token ID: 100","MASK Token ID: 103","Vocab size: 30522"]}],"execution_count":9},{"cell_type":"code","source":"def tokenize_and_mask(texts, \n                      noise=0.15, \n                      tokenizer=tokenizer):\n    encoded_texts = tokenizer(texts, return_tensors=\"tf\", add_special_tokens=True, padding=True, truncation=True, max_length=256)['input_ids']\n    inp_mask = np.random.rand(*encoded_texts.shape) < noise\n    inp_mask[encoded_texts == 101] = False\n    inp_mask[encoded_texts == 102] = False\n    inp_mask[encoded_texts == 0] = False\n    \n    labels = -1 * np.ones(encoded_texts.shape, dtype=int)\n    # Set labels for masked tokens\n    labels[inp_mask] = encoded_texts[inp_mask]\n\n    # Prepare input\n    encoded_texts_masked = np.copy(encoded_texts)\n    # Set input to [MASK] which is the last token for the 90% of tokens\n    # This means leaving 10% unchanged\n    inp_mask_2mask = inp_mask & (np.random.rand(*encoded_texts.shape) < 0.90)\n    encoded_texts_masked[\n        inp_mask_2mask\n    ] = tokenizer.mask_token_id  # mask token is the last in the dict\n\n    # Set 10% to a random token\n    inp_mask_2random = inp_mask_2mask & (np.random.rand(*encoded_texts.shape) < 1 / 9)\n    encoded_texts_masked[inp_mask_2random] = np.random.randint(\n        104, 200, inp_mask_2random.sum()\n    )\n    \n    # Prepare sample_weights to pass to .fit() method\n    sample_weights = np.ones(labels.shape)\n    sample_weights[labels == -1] = 0\n    \n    y_labels = np.copy(encoded_texts)\n\n    return encoded_texts_masked, y_labels, sample_weights\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T01:55:03.045030Z","iopub.execute_input":"2024-11-27T01:55:03.045719Z","iopub.status.idle":"2024-11-27T01:55:03.052693Z","shell.execute_reply.started":"2024-11-27T01:55:03.045685Z","shell.execute_reply":"2024-11-27T01:55:03.051785Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"BATCH_SIZE = 32\nx_masked_train, y_masked_labels, sample_weights = tokenize_and_mask(mlm_data['text'][0:1500000].tolist())\n\nmlm_ds = tf.data.Dataset.from_tensor_slices(\n    (x_masked_train, y_masked_labels)\n)\nmlm_ds = mlm_ds.shuffle(1000).batch(BATCH_SIZE)\nmlm_ds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T01:55:12.643360Z","iopub.execute_input":"2024-11-27T01:55:12.643761Z","iopub.status.idle":"2024-11-27T02:02:53.464616Z","shell.execute_reply.started":"2024-11-27T01:55:12.643722Z","shell.execute_reply":"2024-11-27T02:02:53.463680Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"<_BatchDataset element_spec=(TensorSpec(shape=(None, 164), dtype=tf.int32, name=None), TensorSpec(shape=(None, 164), dtype=tf.int32, name=None))>"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"min_bert_layer = minBert(\n    name = 'minbert',\n    num_layers=4,  # Số lượng lớp encoder\n    d_model=256,   # Kích thước vector ẩn\n    num_heads=8,   # Số lượng head trong multi-head attention\n    dff=1024,      # Số lượng neuron trong feed-forward network\n    vocab_size=tokenizer.vocab_size,  # Kích thước từ vựng\n    dropout_rate=0.1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T02:02:53.465983Z","iopub.execute_input":"2024-11-27T02:02:53.466257Z","iopub.status.idle":"2024-11-27T02:02:53.521096Z","shell.execute_reply.started":"2024-11-27T02:02:53.466230Z","shell.execute_reply":"2024-11-27T02:02:53.520438Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"mlm_model = tf.keras.Sequential([\n    min_bert_layer,\n    tf.keras.layers.Dense(512, activation=\"relu\"),\n    tf.keras.layers.Dense(tokenizer.vocab_size, activation=\"softmax\")\n])  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T02:02:53.522017Z","iopub.execute_input":"2024-11-27T02:02:53.522297Z","iopub.status.idle":"2024-11-27T02:02:53.528224Z","shell.execute_reply.started":"2024-11-27T02:02:53.522270Z","shell.execute_reply":"2024-11-27T02:02:53.527346Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"loss_fuction = tf.keras.losses.SparseCategoricalCrossentropy(\n    from_logits=False,\n    ignore_class= -1,\n)\n\nmlm_model.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n    loss=loss_fuction,\n    metrics=[\"accuracy\"],\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T02:02:53.529691Z","iopub.execute_input":"2024-11-27T02:02:53.529973Z","iopub.status.idle":"2024-11-27T02:02:53.552161Z","shell.execute_reply.started":"2024-11-27T02:02:53.529946Z","shell.execute_reply":"2024-11-27T02:02:53.551300Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"mlm_model.fit(mlm_ds, epochs=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T02:02:53.553118Z","iopub.execute_input":"2024-11-27T02:02:53.553379Z","iopub.status.idle":"2024-11-27T06:18:59.273054Z","shell.execute_reply.started":"2024-11-27T02:02:53.553355Z","shell.execute_reply":"2024-11-27T06:18:59.272203Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/2\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:877: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:877: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:877: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:877: UserWarning: Layer 'self_attention' (of type SelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:877: UserWarning: Layer 'encoder_layer' (of type EncoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n  warnings.warn(\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1732672986.058951     110 service.cc:145] XLA service 0x7c06d40116f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1732672986.059020     110 service.cc:153]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nW0000 00:00:1732672987.093812     110 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1732673005.332578     110 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_16', 224 bytes spill stores, 224 bytes spill loads\n\nI0000 00:00:1732673005.363010     110 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m46875/46875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7711s\u001b[0m 164ms/step - accuracy: 0.9813 - loss: 0.2249\nEpoch 2/2\n\u001b[1m46875/46875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7655s\u001b[0m 163ms/step - accuracy: 0.9919 - loss: 0.0510\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7c0809957700>"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"mlm_model.save('mlmmodel.keras')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T06:45:07.860749Z","iopub.execute_input":"2024-11-27T06:45:07.861206Z","iopub.status.idle":"2024-11-27T06:45:09.118722Z","shell.execute_reply.started":"2024-11-27T06:45:07.861179Z","shell.execute_reply":"2024-11-27T06:45:09.117730Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"restored_model = tf.keras.models.load_model(\n    'mlmmodel.keras',\n    custom_objects={\n        \"minBert\": minBert,\n    }\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T01:03:14.025594Z","iopub.execute_input":"2024-11-27T01:03:14.026536Z","iopub.status.idle":"2024-11-27T01:03:22.046280Z","shell.execute_reply.started":"2024-11-27T01:03:14.026499Z","shell.execute_reply":"2024-11-27T01:03:22.045561Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:877: UserWarning: Layer 'self_attention_4' (of type SelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:877: UserWarning: Layer 'encoder_layer_4' (of type EncoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"mlm_model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T01:03:25.281475Z","iopub.execute_input":"2024-11-27T01:03:25.281858Z","iopub.status.idle":"2024-11-27T01:03:25.303831Z","shell.execute_reply.started":"2024-11-27T01:03:25.281818Z","shell.execute_reply":"2024-11-27T01:03:25.302878Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_4\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ minbert (\u001b[38;5;33mminBert\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │    \u001b[38;5;34m18,334,208\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │       \u001b[38;5;34m131,584\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m30522\u001b[0m)      │    \u001b[38;5;34m15,657,786\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ minbert (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">minBert</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │    <span style=\"color: #00af00; text-decoration-color: #00af00\">18,334,208</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30522</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">15,657,786</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m102,370,736\u001b[0m (390.51 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">102,370,736</span> (390.51 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m34,123,578\u001b[0m (130.17 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,123,578</span> (130.17 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m68,247,158\u001b[0m (260.34 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">68,247,158</span> (260.34 MB)\n</pre>\n"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"min_bert_layer.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T06:19:16.850372Z","iopub.execute_input":"2024-11-27T06:19:16.850741Z","iopub.status.idle":"2024-11-27T06:19:16.870248Z","shell.execute_reply.started":"2024-11-27T06:19:16.850705Z","shell.execute_reply":"2024-11-27T06:19:16.869579Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"minbert\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"minbert\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ positional_embedding            │ ?                      │     \u001b[38;5;34m7,813,632\u001b[0m │\n│ (\u001b[38;5;33mPositionalEmbedding\u001b[0m)           │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_layer (\u001b[38;5;33mEncoderLayer\u001b[0m)    │ ?                      │     \u001b[38;5;34m2,630,144\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_layer_1 (\u001b[38;5;33mEncoderLayer\u001b[0m)  │ ?                      │     \u001b[38;5;34m2,630,144\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_layer_2 (\u001b[38;5;33mEncoderLayer\u001b[0m)  │ ?                      │     \u001b[38;5;34m2,630,144\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_layer_3 (\u001b[38;5;33mEncoderLayer\u001b[0m)  │ ?                      │     \u001b[38;5;34m2,630,144\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ positional_embedding            │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">7,813,632</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbedding</span>)           │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">EncoderLayer</span>)    │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,630,144</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">EncoderLayer</span>)  │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,630,144</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">EncoderLayer</span>)  │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,630,144</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">EncoderLayer</span>)  │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,630,144</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m18,334,208\u001b[0m (69.94 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,334,208</span> (69.94 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m18,334,208\u001b[0m (69.94 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,334,208</span> (69.94 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"min_bert_layer.save(\"min_bert_layer.keras\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T06:19:23.264933Z","iopub.execute_input":"2024-11-27T06:19:23.265282Z","iopub.status.idle":"2024-11-27T06:19:23.545181Z","shell.execute_reply.started":"2024-11-27T06:19:23.265249Z","shell.execute_reply":"2024-11-27T06:19:23.544433Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"restored_model = tf.keras.models.load_model(\n    'min_bert_layer.keras',\n    custom_objects={\n        \"minBert\": minBert,\n        \"EncoderLayer\": EncoderLayer,\n        \"SelfAttention\": SelfAttention,\n        \"FeedForward\": FeedForward,\n        \"BaseAttention\" : BaseAttention,\n        \"PositionalEmbedding\" : PositionalEmbedding\n    }\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T06:24:27.356922Z","iopub.execute_input":"2024-11-27T06:24:27.357984Z","iopub.status.idle":"2024-11-27T06:24:30.044990Z","shell.execute_reply.started":"2024-11-27T06:24:27.357947Z","shell.execute_reply":"2024-11-27T06:24:30.044199Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:877: UserWarning: Layer 'self_attention_8' (of type SelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:877: UserWarning: Layer 'encoder_layer_8' (of type EncoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"restored_model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T01:04:44.834175Z","iopub.execute_input":"2024-11-27T01:04:44.834987Z","iopub.status.idle":"2024-11-27T01:04:44.854275Z","shell.execute_reply.started":"2024-11-27T01:04:44.834952Z","shell.execute_reply":"2024-11-27T01:04:44.853084Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"minbert\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"minbert\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ positional_embedding_2          │ ?                      │     \u001b[38;5;34m7,813,632\u001b[0m │\n│ (\u001b[38;5;33mPositionalEmbedding\u001b[0m)           │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_layer_8 (\u001b[38;5;33mEncoderLayer\u001b[0m)  │ ?                      │     \u001b[38;5;34m2,630,144\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_layer_9 (\u001b[38;5;33mEncoderLayer\u001b[0m)  │ ?                      │     \u001b[38;5;34m2,630,144\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_layer_10 (\u001b[38;5;33mEncoderLayer\u001b[0m) │ ?                      │     \u001b[38;5;34m2,630,144\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_layer_11 (\u001b[38;5;33mEncoderLayer\u001b[0m) │ ?                      │     \u001b[38;5;34m2,630,144\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_22 (\u001b[38;5;33mDropout\u001b[0m)            │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ positional_embedding_2          │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">7,813,632</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbedding</span>)           │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_layer_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">EncoderLayer</span>)  │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,630,144</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_layer_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">EncoderLayer</span>)  │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,630,144</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_layer_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">EncoderLayer</span>) │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,630,144</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_layer_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">EncoderLayer</span>) │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,630,144</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m18,334,208\u001b[0m (69.94 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,334,208</span> (69.94 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m18,334,208\u001b[0m (69.94 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,334,208</span> (69.94 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"restored_model(tf.constant([[1011, 1012]]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T01:04:57.375615Z","iopub.execute_input":"2024-11-27T01:04:57.376215Z","iopub.status.idle":"2024-11-27T01:04:59.389878Z","shell.execute_reply.started":"2024-11-27T01:04:57.376183Z","shell.execute_reply":"2024-11-27T01:04:59.388918Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(1, 2, 256), dtype=float32, numpy=\narray([[[ 7.69535363e-01, -1.21936035e+00, -5.28453887e-01,\n          7.25269496e-01,  7.65354037e-01, -1.09919727e-01,\n          6.66685164e-01,  5.57543099e-01, -1.86943337e-01,\n         -3.65172237e-01, -1.17172098e+00,  7.52176940e-01,\n          5.21580815e-01,  9.68844235e-01,  1.61041594e+00,\n          1.11663975e-01, -1.14915299e+00, -1.63497522e-01,\n          3.11338216e-01,  7.54375681e-02,  2.31324315e-01,\n          9.62701917e-01, -1.12953115e+00,  9.22213316e-01,\n          3.10716480e-01,  2.20776582e+00, -1.25946522e-01,\n         -1.58513904e+00, -4.29644436e-01, -4.48094279e-01,\n          5.56437492e-01, -1.59491450e-01,  2.99311578e-01,\n          2.42751494e-01, -2.80126989e-01,  4.73398060e-01,\n         -1.82507563e+00, -4.06455755e-01, -3.01502705e-01,\n         -7.82541454e-01,  1.00253439e+00, -1.54386535e-01,\n          6.34262525e-03,  1.16350245e+00, -8.27867687e-01,\n          9.56638992e-01, -1.87372506e-01, -5.11880338e-01,\n         -4.04156148e-01,  1.29957229e-01, -8.84489357e-01,\n         -9.62116897e-01, -1.54616266e-01,  1.80953071e-01,\n          1.18253255e+00, -8.55953872e-01, -6.17882133e-01,\n          1.64312434e+00,  2.80989647e+00,  1.33503723e+00,\n         -2.10902005e-01, -1.21923342e-01,  7.65774250e-01,\n         -9.28967834e-01, -2.74319381e-01,  3.93539757e-01,\n         -1.99899793e-01, -1.07274793e-01,  1.41461682e+00,\n          1.12581050e+00, -1.30630052e+00, -1.02652848e-01,\n         -1.17147779e+00,  1.04688358e+00,  2.94988543e-01,\n         -4.94788498e-01, -8.12992513e-01, -1.97490752e-01,\n         -1.87296152e-01,  5.07754207e-01, -8.09184134e-01,\n         -1.23277199e+00,  1.72790670e+00,  7.51025140e-01,\n          1.25316608e+00, -6.43939257e-01, -7.69416094e-01,\n          8.56453538e-01, -5.17761827e-01, -1.25811212e-02,\n          9.85665858e-01, -6.27816439e-01, -1.09066933e-01,\n         -4.04339731e-02,  3.96273434e-01,  2.25057364e-01,\n         -5.27909696e-01, -1.33195353e+00,  3.26157182e-01,\n          1.17634881e+00, -2.54781580e+00,  3.86024654e-01,\n          9.80190039e-01,  1.40693951e+00, -1.07467031e+00,\n         -7.52727091e-01,  7.00052559e-01, -1.29637122e-01,\n          8.36286187e-01, -1.30362168e-01, -2.65688515e+00,\n          2.50124812e-01,  1.62387061e+00, -5.36657035e-01,\n         -1.47990513e+00, -2.17883444e+00, -2.38649893e+00,\n          1.63836002e-01,  7.53917217e-01,  7.27942884e-01,\n          1.38305575e-01,  2.00969505e+00,  3.15569848e-01,\n          7.61980042e-02,  1.82236063e+00,  1.08448160e+00,\n          6.65003061e-01,  3.49222362e-01,  9.14095163e-01,\n         -8.74300659e-01, -3.49558920e-01, -1.71853995e+00,\n          1.70752335e+00, -5.86212337e-01,  1.26019657e+00,\n          1.70593071e+00, -7.83478141e-01,  8.71059597e-01,\n         -1.69751906e+00, -2.88255036e-01,  1.03017843e+00,\n          5.87923348e-01, -1.93885550e-01,  1.60695791e+00,\n         -8.90565515e-01, -5.38229704e-01, -8.70732248e-01,\n          5.70582867e-01, -8.33893836e-01, -6.21073127e-01,\n          9.45594907e-01,  9.93073046e-01,  4.12202068e-02,\n          1.12574089e+00,  2.04385638e+00, -1.10545790e+00,\n         -4.73306775e-01,  1.55308640e+00, -2.05137801e+00,\n          3.88990432e-01,  6.61601782e-01,  2.00335240e+00,\n         -6.36034071e-01, -1.06934834e+00, -3.72451432e-02,\n          1.56881839e-01, -3.90392505e-02,  1.24533847e-01,\n         -5.62873662e-01,  2.91122407e-01,  2.76837647e-01,\n         -2.13195577e-01, -1.14024055e+00, -2.13129711e+00,\n          8.84487748e-01,  6.45888150e-01, -1.24188888e+00,\n          1.91572189e+00, -7.87937164e-01,  3.46336573e-01,\n         -2.55569667e-01,  8.67489219e-01, -4.16832060e-01,\n          1.10421395e+00,  3.60688984e-01,  1.23567712e+00,\n         -3.77023876e-01, -7.86703706e-01, -5.06355822e-01,\n         -6.39788285e-02,  8.78564894e-01, -1.41936409e+00,\n         -1.10135972e+00, -8.91062379e-01, -1.04619898e-01,\n          7.79530779e-02, -2.06440949e+00,  5.19907236e-01,\n         -2.07469463e+00, -6.58236027e-01,  8.89863372e-01,\n          9.64345217e-01,  2.88051367e-01,  7.40520716e-01,\n         -1.37753487e+00,  8.38616788e-01,  1.10000837e+00,\n          5.31319737e-01, -4.81869489e-01,  9.62218940e-01,\n          1.01669097e+00,  1.58694327e-01, -6.08372986e-01,\n          8.50344837e-01, -2.31234050e+00, -1.70162037e-01,\n         -6.25083148e-01,  1.47032976e+00, -7.52425075e-01,\n          1.27218068e+00, -2.68683195e-01, -5.51199555e-01,\n         -2.81828433e-01,  1.86850119e+00,  3.17426741e-01,\n          4.67672139e-01, -3.83128107e-01,  1.45437807e-01,\n         -1.51867464e-01,  1.08346105e+00, -1.05884933e+00,\n          1.24236596e+00, -1.42270446e+00, -2.76949382e+00,\n         -7.17276275e-01,  6.50608301e-01, -6.06748641e-01,\n         -1.53951719e-01, -1.69635856e+00,  6.84163868e-01,\n         -4.32601154e-01,  9.61771488e-01,  1.05881655e+00,\n          1.36562675e-01, -2.35416198e+00, -1.41060084e-01,\n         -1.34898984e+00, -1.09330392e+00, -3.85557264e-01,\n         -1.65001285e+00,  1.14396775e+00,  1.67741507e-01,\n         -7.62513578e-01, -4.49802160e-01, -6.81926906e-01,\n          9.56511125e-04],\n        [ 7.04102159e-01, -1.29682040e+00,  3.49988997e-01,\n         -1.87744439e-01,  1.83235085e+00, -6.34545743e-01,\n          8.69757295e-01, -2.25763649e-01, -8.07926357e-01,\n         -6.69411182e-01,  1.64623111e-01,  8.98256481e-01,\n          9.90310550e-01,  2.84572780e-01,  1.42500091e+00,\n         -4.67528224e-01, -7.58465767e-01,  2.02416360e-01,\n          8.21772873e-01,  9.64930654e-02,  9.44211483e-01,\n          9.45548773e-01, -3.95925045e-01,  5.96318841e-01,\n          3.14686358e-01,  2.05348992e+00, -3.17516953e-01,\n         -1.51351166e+00, -3.24416369e-01, -9.03141260e-01,\n          8.58703673e-01, -9.37647045e-01,  2.63160348e-01,\n          3.08194906e-01, -5.73807538e-01,  4.68807369e-01,\n         -2.66542625e+00, -1.22005180e-01,  5.40522814e-01,\n         -4.95882571e-01,  3.37649971e-01,  8.01669836e-01,\n         -1.87370062e-01,  2.22541785e+00, -2.41773918e-01,\n          1.80349159e+00, -1.31367874e+00, -1.72636077e-01,\n          6.07566051e-02,  3.81329477e-01, -1.42274487e+00,\n         -5.14472485e-01, -1.23302147e-01,  1.10169613e+00,\n          1.14628959e+00, -2.59918630e-01,  3.80279928e-01,\n          1.38969445e+00,  2.16597819e+00,  8.51741552e-01,\n         -1.24135888e+00,  5.72283044e-02,  1.22121441e+00,\n         -7.21130013e-01,  8.17108825e-02,  8.28496277e-01,\n         -2.12742627e-01, -1.75365865e-01,  9.45795536e-01,\n          1.28472042e+00, -1.50522685e+00, -2.14764923e-01,\n         -1.21336174e+00,  3.92099202e-01, -4.95631635e-01,\n         -1.60913527e-01, -2.48442106e-02, -5.24116933e-01,\n          2.31929615e-01, -5.35972357e-01, -1.01360130e+00,\n         -5.33092499e-01,  2.04924750e+00, -3.79182518e-01,\n          3.63101900e-01,  9.08280089e-02, -1.63513637e+00,\n          1.23729050e+00, -5.18047154e-01, -5.75872064e-01,\n          1.63451359e-01, -2.18527228e-01, -5.59803784e-01,\n         -7.49422610e-01, -3.86428505e-01,  2.29557548e-02,\n         -3.95668268e-01, -2.03035802e-01,  6.76221430e-01,\n          1.61575139e+00, -2.35334086e+00,  3.16396236e-01,\n          8.85061264e-01,  1.39680064e+00, -6.10811591e-01,\n         -4.66849804e-02,  3.78229141e-01,  2.26303935e-02,\n         -6.03532866e-02,  3.98322612e-01, -2.19763899e+00,\n          3.53684425e-01,  1.22511041e+00, -1.61035931e+00,\n         -1.42417884e+00, -2.79756808e+00, -2.13967466e+00,\n         -2.49278784e-01,  2.61820525e-01,  7.88216174e-01,\n          1.05047512e+00,  1.49477243e+00, -1.88861877e-01,\n          1.16598940e+00,  1.21629655e-01,  1.41457474e+00,\n          8.80888999e-01,  1.83151782e-01,  1.46367049e+00,\n         -1.39967906e+00, -6.53563142e-01, -1.46648443e+00,\n          1.33957076e+00, -2.25630701e-01,  7.51510978e-01,\n          1.06424284e+00, -1.51141536e+00,  4.87311818e-02,\n         -1.51196861e+00, -4.81043994e-01,  2.43684709e-01,\n          1.03430307e+00, -1.82179302e-01,  1.33243823e+00,\n         -2.32963338e-01, -6.49811089e-01, -1.46120179e+00,\n          2.83009410e-02, -2.92634010e-01, -9.72257614e-01,\n          1.13853192e+00,  8.03054988e-01, -4.58079129e-02,\n          1.62264144e+00,  2.20181966e+00, -1.42288017e+00,\n         -6.23718917e-01,  1.14273012e+00, -2.54480362e+00,\n          2.31959164e-01,  9.34195459e-01,  1.14598966e+00,\n         -5.81073940e-01, -5.07798016e-01,  8.77035260e-02,\n          7.95564950e-01, -1.43208981e-01, -5.96465841e-02,\n         -5.83019435e-01,  1.21306074e+00,  9.14982617e-01,\n         -3.54366601e-01, -9.85623479e-01, -1.57068300e+00,\n          8.58611286e-01,  3.68252210e-03, -1.03782821e+00,\n          2.01593041e+00, -1.29262745e+00,  6.78719699e-01,\n         -2.37638682e-01,  1.49132776e+00, -2.34791756e-01,\n          4.81681943e-01,  8.03932190e-01,  9.91709411e-01,\n         -5.07871434e-02, -6.30935550e-01, -9.74912107e-01,\n          3.05224538e-01,  9.81827557e-01, -1.11185157e+00,\n         -8.06670636e-02, -1.18516994e+00, -7.83759117e-01,\n          8.22437763e-01, -1.12925828e+00,  3.66200805e-01,\n         -2.18187404e+00,  3.25212359e-01,  4.21112567e-01,\n          1.23098898e+00,  4.62235808e-01,  8.62646878e-01,\n         -1.65444636e+00,  4.69493926e-01,  1.69131374e+00,\n          8.82396042e-01, -1.01689541e+00,  4.45134521e-01,\n          9.91816998e-01,  1.13836527e-01, -8.23041141e-01,\n          1.06306946e+00, -1.99310970e+00, -1.26378679e+00,\n          2.74357170e-01,  1.43447265e-01, -3.94562691e-01,\n          9.97255504e-01, -1.70418620e-01, -3.72951537e-01,\n         -1.17843919e-01,  1.72577393e+00,  4.49150026e-01,\n          6.25964999e-01, -4.03284311e-01,  8.96273673e-01,\n         -1.99323654e-01,  1.11196136e+00, -1.12731445e+00,\n          1.42857897e+00, -1.22109711e+00, -1.79294109e+00,\n         -4.99514073e-01,  3.50264460e-02, -3.13856900e-02,\n          7.49316394e-01, -1.75595903e+00,  4.30921540e-02,\n         -6.54015183e-01,  7.10905612e-01, -5.13205156e-02,\n          2.61393607e-01, -2.42319632e+00, -3.72797251e-02,\n         -1.18600786e+00, -4.59528863e-01, -8.55518281e-01,\n         -2.12890911e+00,  1.22244489e+00,  5.93560755e-01,\n         -2.60247856e-01, -1.30217373e+00, -8.97937000e-01,\n          1.60491735e-01]]], dtype=float32)>"},"metadata":{}}],"execution_count":22}]}